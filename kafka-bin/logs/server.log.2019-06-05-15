[2019-06-05 15:39:59,911] WARN Exception causing close of session 0x1000842cbd40000: 远程主机强迫关闭了一个现有的连接。 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-06-05 15:40:00,700] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:53792 which had sessionid 0x1000842cbd40000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-06-05 15:40:01,976] INFO Expiring session 0x1000842cbd40000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:40:02,001] INFO Processed session termination for sessionid: 0x1000842cbd40000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:07,449] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-06-05 15:46:09,448] INFO starting (kafka.server.KafkaServer)
[2019-06-05 15:46:09,449] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-06-05 15:46:09,672] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-06-05 15:46:09,705] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:09,705] INFO Client environment:host.name=xqy-HP (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:09,706] INFO Client environment:java.version=1.8.0_111 (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:09,706] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:09,706] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_111\jre (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:09,706] INFO Client environment:java.class.path=C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\activation-1.1.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\argparse4j-0.7.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\audience-annotations-0.5.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\commons-lang3-3.8.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-api-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-basic-auth-extension-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-file-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-json-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-runtime-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-transforms-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\guava-20.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\hk2-api-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\hk2-locator-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\hk2-utils-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-annotations-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-core-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-databind-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-datatype-jdk8-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-jaxrs-base-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javassist-3.22.0-CR2.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.annotation-api-1.2.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.inject-1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.inject-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.servlet-api-3.1.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.ws.rs-api-2.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jaxb-api-2.3.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-client-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-common-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-container-servlet-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-container-servlet-core-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-hk2-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-media-jaxb-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-server-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-client-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-continuation-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-http-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-io-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-security-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-server-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-servlet-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-servlets-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-util-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jopt-simple-5.0.4.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-clients-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-log4j-appender-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-streams-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-streams-examples-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-streams-scala_2.12-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-streams-test-utils-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-tools-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-javadoc.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-javadoc.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-scaladoc.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-scaladoc.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-sources.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-sources.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-test-sources.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-test-sources.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-test.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-test.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\log4j-1.2.17.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\lz4-java-1.5.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\maven-artifact-3.6.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\metrics-core-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\osgi-resource-locator-1.0.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\plexus-utils-3.1.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\reflections-0.9.11.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\rocksdbjni-5.15.10.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\scala-library-2.12.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\scala-logging_2.12-3.9.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\scala-reflect-2.12.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\slf4j-api-1.7.25.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\slf4j-log4j12-1.7.25.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\snappy-java-1.1.7.2.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\validation-api-1.1.0.Final.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\zkclient-0.11.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\zookeeper-3.4.13.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:09,708] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_111\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\oracle\product\10.2.0\db_1\bin;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Intel\iCLS Client\;C:\Program Files\Common Files\Microsoft Shared\Windows Live;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Hewlett-Packard\SimplePass;C:\Program Files\Windows Live\Shared;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\Java\jdk1.8.0_111\bin;C:\Users\xqy\Downloads\apache-maven-3.5.0-bin\apache-maven-3.5.0\bin;C:\php\php\php-5.4.45;C:\php\php\php-5.4.45\ext;C:\Program Files\Google\Chrome\Application;C:\MinGW\bin;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Users\xqy\Desktop\Download\download\gradle-4.6\bin;C:\Program Files\Git\cmd;C:\Program Files\dotnet\;C:\Program Files\PxMEWNET;C:\Program Files\ojdkbuild\java-1.10.0-openjdk-1.10.0.1-1\bin;C:\Javalib\antlr-4.7.1-complete.jar;C:\Program Files\nodejs\;C:\Program Files (x86)\STMicroelectronics\STM32 ST-LINK Utility\ST-LINK Utility;C:\Users\xqy\Desktop\apache-tomcat-9.0.0.M22 - 副本\apache-ant-1.10.5\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\PuTTY\;C:\Program Files\sbt\bin;C:\Program Files\scala\bin;C:\Users\xqy\Desktop\projects\OpenCV\opencv\build\java\x86;C:\Program Files\OpenSSL-Win32\bin;C:\Program Files\GNU Tools ARM Embedded\8 2018-q4-major\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:09,708] INFO Client environment:java.io.tmpdir=C:\Users\xqy\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:09,709] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:09,709] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:09,709] INFO Client environment:os.arch=x86 (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:09,709] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:09,709] INFO Client environment:user.name=xqy (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:09,709] INFO Client environment:user.home=C:\Users\xqy (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:09,709] INFO Client environment:user.dir=C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:09,711] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@130745 (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:09,825] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-06-05 15:46:09,838] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-06-05 15:46:09,840] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-06-05 15:46:09,862] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62173 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-06-05 15:46:09,921] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62173 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:46:10,077] INFO Established session 0x1000842cbd40001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62173 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:46:10,080] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000842cbd40001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-06-05 15:46:10,086] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-06-05 15:46:10,454] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40001 type:create cxid:0x1 zxid:0x130 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:10,609] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40001 type:create cxid:0x2 zxid:0x131 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:10,738] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40001 type:create cxid:0x3 zxid:0x132 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:10,800] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40001 type:create cxid:0x4 zxid:0x133 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:10,883] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40001 type:create cxid:0x5 zxid:0x134 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:10,955] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40001 type:create cxid:0x6 zxid:0x135 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:11,029] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40001 type:create cxid:0x7 zxid:0x136 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:11,177] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40001 type:create cxid:0x8 zxid:0x137 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:11,229] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40001 type:create cxid:0x9 zxid:0x138 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:11,307] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40001 type:create cxid:0xa zxid:0x139 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:11,384] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40001 type:create cxid:0xb zxid:0x13a txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:11,502] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40001 type:create cxid:0xc zxid:0x13b txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:11,567] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40001 type:create cxid:0xd zxid:0x13c txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:12,158] INFO Cluster ID = nZyUWUdKQ3yvmijW4epzyw (kafka.server.KafkaServer)
[2019-06-05 15:46:12,351] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-06-05 15:46:12,368] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-06-05 15:46:12,584] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-06-05 15:46:12,584] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-06-05 15:46:12,586] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-06-05 15:46:12,783] INFO Loading logs. (kafka.log.LogManager)
[2019-06-05 15:46:13,283] WARN [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\distributed-video1-0\00000000000000005274.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\distributed-video1-0\00000000000000005274.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1559717211923}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:13,286] INFO [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 5274 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:13,344] INFO [ProducerStateManager partition=distributed-video1-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\distributed-video1-0\00000000000000005274.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:14,861] INFO [ProducerStateManager partition=distributed-video1-0] Writing producer snapshot at offset 6044 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:14,881] INFO [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 5274 (kafka.log.Log)
[2019-06-05 15:46:14,882] INFO [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 5274 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:14,885] INFO [ProducerStateManager partition=distributed-video1-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\distributed-video1-0\00000000000000005274.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:15,221] INFO [ProducerStateManager partition=distributed-video1-0] Writing producer snapshot at offset 6044 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:15,386] INFO [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 6044 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:15,390] INFO [ProducerStateManager partition=distributed-video1-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\distributed-video1-0\00000000000000006044.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:15,392] INFO [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 5274 and log end offset 6044 in 2479 ms (kafka.log.Log)
[2019-06-05 15:46:15,429] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 76 (kafka.log.Log)
[2019-06-05 15:46:15,429] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 76 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:15,433] INFO [ProducerStateManager partition=javainuse-topic-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\javainuse-topic-0\00000000000000000076.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:15,536] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 76 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:15,539] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 76 and log end offset 76 in 136 ms (kafka.log.Log)
[2019-06-05 15:46:15,550] INFO [Log partition=streams-plaintext-input-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:15,551] INFO [Log partition=streams-plaintext-input-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:15,645] INFO [Log partition=streams-plaintext-input-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:15,648] INFO [Log partition=streams-plaintext-input-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 103 ms (kafka.log.Log)
[2019-06-05 15:46:15,657] INFO [Log partition=streams-wordcount-output-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:15,658] INFO [Log partition=streams-wordcount-output-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:15,756] INFO [Log partition=streams-wordcount-output-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:15,760] INFO [Log partition=streams-wordcount-output-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 110 ms (kafka.log.Log)
[2019-06-05 15:46:15,768] INFO [Log partition=test-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:15,768] INFO [Log partition=test-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:15,878] INFO [Log partition=test-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:15,881] INFO [Log partition=test-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 118 ms (kafka.log.Log)
[2019-06-05 15:46:15,890] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:15,891] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,003] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,007] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 122 ms (kafka.log.Log)
[2019-06-05 15:46:16,024] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:16,024] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,103] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,106] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 89 ms (kafka.log.Log)
[2019-06-05 15:46:16,116] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:16,116] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,200] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,204] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 93 ms (kafka.log.Log)
[2019-06-05 15:46:16,213] WARN [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-11\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-11\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553753082425}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:16,213] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,216] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:16,217] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:16,217] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,224] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:16,311] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,314] INFO [ProducerStateManager partition=__consumer_offsets-11] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-11\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:16,314] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 107 ms (kafka.log.Log)
[2019-06-05 15:46:16,322] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:16,322] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,391] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,394] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 77 ms (kafka.log.Log)
[2019-06-05 15:46:16,430] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:16,430] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,544] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,547] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 148 ms (kafka.log.Log)
[2019-06-05 15:46:16,556] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:16,556] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,634] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,637] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 87 ms (kafka.log.Log)
[2019-06-05 15:46:16,645] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:16,645] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,702] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,705] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 66 ms (kafka.log.Log)
[2019-06-05 15:46:16,714] WARN [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750682425}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:16,714] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,720] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:16,722] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:16,723] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,729] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:16,822] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,825] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:16,825] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 116 ms (kafka.log.Log)
[2019-06-05 15:46:16,833] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:16,833] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,912] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,914] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 87 ms (kafka.log.Log)
[2019-06-05 15:46:16,922] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:16,923] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,980] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:16,983] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-06-05 15:46:16,990] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:16,990] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:17,077] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:17,080] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 95 ms (kafka.log.Log)
[2019-06-05 15:46:17,090] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:17,090] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:17,211] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:17,215] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 132 ms (kafka.log.Log)
[2019-06-05 15:46:17,250] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:17,250] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:17,511] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:17,515] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 297 ms (kafka.log.Log)
[2019-06-05 15:46:17,688] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:17,688] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:17,836] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:17,842] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 161 ms (kafka.log.Log)
[2019-06-05 15:46:17,851] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:17,851] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:17,936] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:17,940] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 95 ms (kafka.log.Log)
[2019-06-05 15:46:17,945] WARN [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-23\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-23\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750082436}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:17,946] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:17,951] INFO [ProducerStateManager partition=__consumer_offsets-23] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:17,952] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:17,952] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:17,958] INFO [ProducerStateManager partition=__consumer_offsets-23] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:18,044] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,046] INFO [ProducerStateManager partition=__consumer_offsets-23] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-23\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:18,047] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 106 ms (kafka.log.Log)
[2019-06-05 15:46:18,052] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Found file C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-06-05 15:46:18,053] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Deleting index files with suffix  for baseFile C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.index (kafka.log.Log)
[2019-06-05 15:46:18,067] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Recovering unflushed segment 3 (kafka.log.Log)
[2019-06-05 15:46:18,067] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,071] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:18,073] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:18,136] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,140] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:18,141] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 4 in 93 ms (kafka.log.Log)
[2019-06-05 15:46:18,149] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:18,149] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,233] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,237] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 94 ms (kafka.log.Log)
[2019-06-05 15:46:18,245] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:18,245] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,323] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,326] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 87 ms (kafka.log.Log)
[2019-06-05 15:46:18,334] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:18,357] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,425] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,429] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 101 ms (kafka.log.Log)
[2019-06-05 15:46:18,442] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:18,443] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,544] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,548] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 116 ms (kafka.log.Log)
[2019-06-05 15:46:18,556] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:18,556] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,681] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,683] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 133 ms (kafka.log.Log)
[2019-06-05 15:46:18,690] WARN [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750082427}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:18,690] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,696] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:18,698] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:18,698] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,704] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:18,833] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,837] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:18,837] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 152 ms (kafka.log.Log)
[2019-06-05 15:46:18,845] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:18,845] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,933] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:18,936] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 98 ms (kafka.log.Log)
[2019-06-05 15:46:18,942] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:18,942] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,022] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,026] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 88 ms (kafka.log.Log)
[2019-06-05 15:46:19,054] WARN [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750682424}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:19,055] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,060] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:19,061] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:19,062] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,067] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:19,167] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,169] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:19,169] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 142 ms (kafka.log.Log)
[2019-06-05 15:46:19,177] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:19,178] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,267] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,270] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 99 ms (kafka.log.Log)
[2019-06-05 15:46:19,276] WARN [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553756682423}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:19,277] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,296] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:19,299] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:19,299] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,306] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:19,389] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,392] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:19,392] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 121 ms (kafka.log.Log)
[2019-06-05 15:46:19,399] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:19,400] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,478] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,480] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 86 ms (kafka.log.Log)
[2019-06-05 15:46:19,485] WARN [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750082439}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:19,485] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,490] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:19,491] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:19,491] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,496] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:19,589] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,592] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:19,592] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 111 ms (kafka.log.Log)
[2019-06-05 15:46:19,598] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:19,598] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,656] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,659] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 66 ms (kafka.log.Log)
[2019-06-05 15:46:19,665] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:19,665] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,733] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,736] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 75 ms (kafka.log.Log)
[2019-06-05 15:46:19,743] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:19,743] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,844] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:19,847] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 109 ms (kafka.log.Log)
[2019-06-05 15:46:19,854] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:19,859] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,011] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,015] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 166 ms (kafka.log.Log)
[2019-06-05 15:46:20,024] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:20,024] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,092] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,096] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 79 ms (kafka.log.Log)
[2019-06-05 15:46:20,144] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:20,144] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,248] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,251] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 154 ms (kafka.log.Log)
[2019-06-05 15:46:20,258] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:20,259] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,378] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,381] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 128 ms (kafka.log.Log)
[2019-06-05 15:46:20,395] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:20,404] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,478] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,481] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 92 ms (kafka.log.Log)
[2019-06-05 15:46:20,488] WARN [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-44\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-44\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553818654937}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:20,488] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,500] INFO [ProducerStateManager partition=__consumer_offsets-44] Writing producer snapshot at offset 15 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:20,502] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:20,503] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,510] INFO [ProducerStateManager partition=__consumer_offsets-44] Writing producer snapshot at offset 15 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:20,600] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,602] INFO [ProducerStateManager partition=__consumer_offsets-44] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-44\00000000000000000015.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:20,602] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 15 in 119 ms (kafka.log.Log)
[2019-06-05 15:46:20,608] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:20,608] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,700] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,704] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 101 ms (kafka.log.Log)
[2019-06-05 15:46:20,712] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:20,712] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,811] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,814] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 109 ms (kafka.log.Log)
[2019-06-05 15:46:20,820] WARN [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553751882423}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:20,821] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,825] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:20,827] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:20,827] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,833] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:20,890] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,892] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:20,892] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 76 ms (kafka.log.Log)
[2019-06-05 15:46:20,898] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:20,899] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,989] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:20,991] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 98 ms (kafka.log.Log)
[2019-06-05 15:46:20,996] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:20,996] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:21,078] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:21,081] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 89 ms (kafka.log.Log)
[2019-06-05 15:46:21,087] WARN [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-5\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-5\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750682426}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:21,088] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:21,094] INFO [ProducerStateManager partition=__consumer_offsets-5] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:21,095] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:21,095] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:21,103] INFO [ProducerStateManager partition=__consumer_offsets-5] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:21,189] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:21,192] INFO [ProducerStateManager partition=__consumer_offsets-5] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-5\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:21,192] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 110 ms (kafka.log.Log)
[2019-06-05 15:46:21,198] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:21,198] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:21,300] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:21,303] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 110 ms (kafka.log.Log)
[2019-06-05 15:46:21,309] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:21,309] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:21,458] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:21,460] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 156 ms (kafka.log.Log)
[2019-06-05 15:46:21,466] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:21,466] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:21,470] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:21,555] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:21,558] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-8\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:21,558] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 97 ms (kafka.log.Log)
[2019-06-05 15:46:21,565] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:21,565] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:21,656] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:21,658] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 99 ms (kafka.log.Log)
[2019-06-05 15:46:21,661] INFO Logs loading complete in 8878 ms. (kafka.log.LogManager)
[2019-06-05 15:46:21,695] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-06-05 15:46:21,697] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-06-05 15:46:23,358] ERROR Failed to clean up log for __consumer_offsets-24 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.cleaned -> C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.swap: 另一个程序正在使用此文件，进程无法访问。

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:805)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:205)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:490)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:1978)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:1978)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:1978)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:580)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
	Suppressed: java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.cleaned -> C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.swap: 另一个程序正在使用此文件，进程无法访问。

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:802)
		... 16 more
[2019-06-05 15:46:23,500] INFO Awaiting socket connections on s0.0.0.0:9092. (kafka.network.Acceptor)
[2019-06-05 15:46:24,232] ERROR Failed to clean up log for __consumer_offsets-24 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.cleaned: 另一个程序正在使用此文件，进程无法访问。

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2236)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:643)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-06-05 15:46:24,594] ERROR Failed to clean up log for __consumer_offsets-24 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.cleaned: 另一个程序正在使用此文件，进程无法访问。

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2236)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:643)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-06-05 15:46:24,713] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-06-05 15:46:24,716] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-06-05 15:46:25,009] ERROR Failed to clean up log for __consumer_offsets-24 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.cleaned: 另一个程序正在使用此文件，进程无法访问。

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2236)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:643)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-06-05 15:46:25,142] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-06-05 15:46:25,143] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-06-05 15:46:25,143] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-06-05 15:46:25,143] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-06-05 15:46:25,297] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-06-05 15:46:25,300] INFO [ReplicaManager broker=0] Stopping serving replicas in dir C:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-06-05 15:46:25,436] ERROR Failed to clean up log for __consumer_offsets-24 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.cleaned: 另一个程序正在使用此文件，进程无法访问。

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2236)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:643)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-06-05 15:46:25,638] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-06-05 15:46:25,639] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-06-05 15:46:25,643] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-06-05 15:46:25,643] INFO Stopping serving logs in dir C:\tmp\kafka-logs (kafka.log.LogManager)
[2019-06-05 15:46:25,784] ERROR Shutdown broker because all log dirs in C:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-06-05 15:46:26,149] WARN Exception causing close of session 0x1000842cbd40001: 远程主机强迫关闭了一个现有的连接。 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-06-05 15:46:26,153] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62173 which had sessionid 0x1000842cbd40001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-06-05 15:46:31,975] INFO Expiring session 0x1000842cbd40001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:46:31,975] INFO Processed session termination for sessionid: 0x1000842cbd40001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:37,752] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-06-05 15:46:38,811] INFO starting (kafka.server.KafkaServer)
[2019-06-05 15:46:38,813] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-06-05 15:46:38,863] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-06-05 15:46:38,876] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:38,876] INFO Client environment:host.name=xqy-HP (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:38,877] INFO Client environment:java.version=1.8.0_111 (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:38,877] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:38,877] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_111\jre (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:38,877] INFO Client environment:java.class.path=C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\activation-1.1.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\argparse4j-0.7.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\audience-annotations-0.5.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\commons-lang3-3.8.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-api-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-basic-auth-extension-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-file-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-json-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-runtime-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-transforms-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\guava-20.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\hk2-api-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\hk2-locator-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\hk2-utils-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-annotations-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-core-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-databind-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-datatype-jdk8-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-jaxrs-base-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javassist-3.22.0-CR2.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.annotation-api-1.2.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.inject-1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.inject-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.servlet-api-3.1.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.ws.rs-api-2.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jaxb-api-2.3.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-client-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-common-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-container-servlet-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-container-servlet-core-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-hk2-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-media-jaxb-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-server-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-client-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-continuation-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-http-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-io-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-security-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-server-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-servlet-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-servlets-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-util-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jopt-simple-5.0.4.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-clients-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-log4j-appender-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-streams-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-streams-examples-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-streams-scala_2.12-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-streams-test-utils-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-tools-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-javadoc.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-javadoc.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-scaladoc.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-scaladoc.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-sources.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-sources.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-test-sources.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-test-sources.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-test.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-test.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\log4j-1.2.17.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\lz4-java-1.5.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\maven-artifact-3.6.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\metrics-core-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\osgi-resource-locator-1.0.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\plexus-utils-3.1.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\reflections-0.9.11.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\rocksdbjni-5.15.10.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\scala-library-2.12.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\scala-logging_2.12-3.9.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\scala-reflect-2.12.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\slf4j-api-1.7.25.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\slf4j-log4j12-1.7.25.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\snappy-java-1.1.7.2.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\validation-api-1.1.0.Final.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\zkclient-0.11.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\zookeeper-3.4.13.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:38,879] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_111\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\oracle\product\10.2.0\db_1\bin;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Intel\iCLS Client\;C:\Program Files\Common Files\Microsoft Shared\Windows Live;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Hewlett-Packard\SimplePass;C:\Program Files\Windows Live\Shared;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\Java\jdk1.8.0_111\bin;C:\Users\xqy\Downloads\apache-maven-3.5.0-bin\apache-maven-3.5.0\bin;C:\php\php\php-5.4.45;C:\php\php\php-5.4.45\ext;C:\Program Files\Google\Chrome\Application;C:\MinGW\bin;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Users\xqy\Desktop\Download\download\gradle-4.6\bin;C:\Program Files\Git\cmd;C:\Program Files\dotnet\;C:\Program Files\PxMEWNET;C:\Program Files\ojdkbuild\java-1.10.0-openjdk-1.10.0.1-1\bin;C:\Javalib\antlr-4.7.1-complete.jar;C:\Program Files\nodejs\;C:\Program Files (x86)\STMicroelectronics\STM32 ST-LINK Utility\ST-LINK Utility;C:\Users\xqy\Desktop\apache-tomcat-9.0.0.M22 - 副本\apache-ant-1.10.5\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\PuTTY\;C:\Program Files\sbt\bin;C:\Program Files\scala\bin;C:\Users\xqy\Desktop\projects\OpenCV\opencv\build\java\x86;C:\Program Files\OpenSSL-Win32\bin;C:\Program Files\GNU Tools ARM Embedded\8 2018-q4-major\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:38,879] INFO Client environment:java.io.tmpdir=C:\Users\xqy\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:38,879] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:38,879] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:38,880] INFO Client environment:os.arch=x86 (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:38,880] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:38,880] INFO Client environment:user.name=xqy (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:38,880] INFO Client environment:user.home=C:\Users\xqy (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:38,880] INFO Client environment:user.dir=C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:38,882] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@130745 (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:46:38,918] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-06-05 15:46:38,920] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-06-05 15:46:38,922] INFO Accepted socket connection from /127.0.0.1:62212 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-06-05 15:46:38,922] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-06-05 15:46:38,931] INFO Client attempting to establish new session at /127.0.0.1:62212 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:46:38,997] INFO Established session 0x1000842cbd40002 with negotiated timeout 6000 for client /127.0.0.1:62212 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:46:39,000] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000842cbd40002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-06-05 15:46:39,005] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-06-05 15:46:39,064] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40002 type:create cxid:0x1 zxid:0x13f txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:39,158] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40002 type:create cxid:0x2 zxid:0x140 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:39,212] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40002 type:create cxid:0x3 zxid:0x141 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:39,281] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40002 type:create cxid:0x4 zxid:0x142 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:39,345] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40002 type:create cxid:0x5 zxid:0x143 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:39,461] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40002 type:create cxid:0x6 zxid:0x144 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:39,531] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40002 type:create cxid:0x7 zxid:0x145 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:39,559] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40002 type:create cxid:0x8 zxid:0x146 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:39,653] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40002 type:create cxid:0x9 zxid:0x147 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:39,692] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40002 type:create cxid:0xa zxid:0x148 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:39,768] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40002 type:create cxid:0xb zxid:0x149 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:39,817] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40002 type:create cxid:0xc zxid:0x14a txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:39,868] INFO Got user-level KeeperException when processing sessionid:0x1000842cbd40002 type:create cxid:0xd zxid:0x14b txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:46:40,188] INFO Cluster ID = nZyUWUdKQ3yvmijW4epzyw (kafka.server.KafkaServer)
[2019-06-05 15:46:40,303] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-06-05 15:46:40,321] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-06-05 15:46:40,363] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-06-05 15:46:40,365] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-06-05 15:46:40,366] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-06-05 15:46:40,434] INFO Loading logs. (kafka.log.LogManager)
[2019-06-05 15:46:40,541] WARN [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\distributed-video1-0\00000000000000005274.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\distributed-video1-0\00000000000000005274.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1559717211923}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:40,542] INFO [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 5274 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:40,577] INFO [ProducerStateManager partition=distributed-video1-0] Writing producer snapshot at offset 5274 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:40,845] INFO [ProducerStateManager partition=distributed-video1-0] Writing producer snapshot at offset 6044 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:40,849] INFO [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 5274 (kafka.log.Log)
[2019-06-05 15:46:40,853] INFO [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 5274 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:40,860] INFO [ProducerStateManager partition=distributed-video1-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\distributed-video1-0\00000000000000005274.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,053] INFO [ProducerStateManager partition=distributed-video1-0] Writing producer snapshot at offset 6044 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,170] INFO [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 6044 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,174] INFO [ProducerStateManager partition=distributed-video1-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\distributed-video1-0\00000000000000006044.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,182] INFO [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 5274 and log end offset 6044 in 687 ms (kafka.log.Log)
[2019-06-05 15:46:41,200] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 76 (kafka.log.Log)
[2019-06-05 15:46:41,201] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 76 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,203] INFO [ProducerStateManager partition=javainuse-topic-0] Writing producer snapshot at offset 76 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,208] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 76 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,211] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 76 and log end offset 76 in 18 ms (kafka.log.Log)
[2019-06-05 15:46:41,221] INFO [Log partition=streams-plaintext-input-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,221] INFO [Log partition=streams-plaintext-input-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,235] INFO [Log partition=streams-plaintext-input-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,238] INFO [Log partition=streams-plaintext-input-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-06-05 15:46:41,249] INFO [Log partition=streams-wordcount-output-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,250] INFO [Log partition=streams-wordcount-output-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,256] INFO [Log partition=streams-wordcount-output-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,259] INFO [Log partition=streams-wordcount-output-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-06-05 15:46:41,269] INFO [Log partition=test-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,270] INFO [Log partition=test-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,275] INFO [Log partition=test-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,277] INFO [Log partition=test-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-06-05 15:46:41,285] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,285] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,290] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,293] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-06-05 15:46:41,303] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,303] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,308] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,310] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-06-05 15:46:41,320] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,320] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,325] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,329] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-06-05 15:46:41,339] WARN [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-11\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-11\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553753082425}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:41,339] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,351] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,353] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,353] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,361] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,434] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,437] INFO [ProducerStateManager partition=__consumer_offsets-11] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-11\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,437] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 103 ms (kafka.log.Log)
[2019-06-05 15:46:41,446] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,448] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,455] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,457] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-06-05 15:46:41,466] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,466] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,472] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,475] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-06-05 15:46:41,485] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,485] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,490] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,493] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-06-05 15:46:41,502] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,502] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,510] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,516] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-06-05 15:46:41,524] WARN [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750682425}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:41,525] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,531] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,534] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,534] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,542] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,623] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,627] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,628] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 109 ms (kafka.log.Log)
[2019-06-05 15:46:41,638] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,638] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,644] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,646] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-06-05 15:46:41,654] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,655] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,674] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,677] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-06-05 15:46:41,687] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,687] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,692] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,695] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-06-05 15:46:41,703] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,704] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,709] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,712] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-06-05 15:46:41,722] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,726] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,733] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,736] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-06-05 15:46:41,743] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,743] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,750] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,753] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-06-05 15:46:41,760] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,760] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,766] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,769] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-06-05 15:46:41,776] WARN [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-23\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-23\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750082436}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:41,776] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,782] INFO [ProducerStateManager partition=__consumer_offsets-23] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,784] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:41,784] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,790] INFO [ProducerStateManager partition=__consumer_offsets-23] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,868] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,871] INFO [ProducerStateManager partition=__consumer_offsets-23] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-23\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,871] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 100 ms (kafka.log.Log)
[2019-06-05 15:46:41,875] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Found file C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-06-05 15:46:41,876] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Deleting index files with suffix  for baseFile C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.index (kafka.log.Log)
[2019-06-05 15:46:41,877] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Found file C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2019-06-05 15:46:41,877] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Deleting index files with suffix  for baseFile C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.log (kafka.log.Log)
[2019-06-05 15:46:41,880] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Deleting index files with suffix .swap for baseFile C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.log (kafka.log.Log)
[2019-06-05 15:46:41,892] WARN [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000003.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000003.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1559720384087}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:41,893] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,896] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,900] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,901] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Recovering unflushed segment 3 (kafka.log.Log)
[2019-06-05 15:46:41,902] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,905] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,909] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,990] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:41,994] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:41,994] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 4 in 121 ms (kafka.log.Log)
[2019-06-05 15:46:42,002] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,002] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,008] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,011] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-06-05 15:46:42,019] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,020] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,025] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,027] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-06-05 15:46:42,037] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,039] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,044] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,047] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-06-05 15:46:42,061] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,061] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,068] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,071] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-06-05 15:46:42,077] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,077] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,082] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,085] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-06-05 15:46:42,092] WARN [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750082427}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:42,092] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,097] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:42,099] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,099] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,105] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:42,190] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,192] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:42,192] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 106 ms (kafka.log.Log)
[2019-06-05 15:46:42,198] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,199] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,204] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,207] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-06-05 15:46:42,214] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,214] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,219] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,222] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-06-05 15:46:42,229] WARN [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750682424}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:42,230] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,235] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:42,237] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,238] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,243] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:42,323] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,326] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:42,327] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 103 ms (kafka.log.Log)
[2019-06-05 15:46:42,333] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,334] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,338] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,340] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-06-05 15:46:42,348] WARN [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553756682423}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:42,348] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,352] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:42,353] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,354] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,358] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:42,473] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,475] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:42,476] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 134 ms (kafka.log.Log)
[2019-06-05 15:46:42,483] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,483] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,493] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,495] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-06-05 15:46:42,503] WARN [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750082439}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:42,503] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,508] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:42,509] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,510] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,516] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:42,648] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,651] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:42,652] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 154 ms (kafka.log.Log)
[2019-06-05 15:46:42,659] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,659] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,667] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,669] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-06-05 15:46:42,674] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,674] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,680] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,683] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-06-05 15:46:42,690] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,690] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,696] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,700] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-06-05 15:46:42,707] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,708] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,715] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,719] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-06-05 15:46:42,726] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,726] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,732] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,735] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-06-05 15:46:42,741] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,741] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,747] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,750] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-06-05 15:46:42,758] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,758] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,764] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,767] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-06-05 15:46:42,775] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,775] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,782] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,785] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-06-05 15:46:42,792] WARN [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-44\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-44\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553818654937}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:42,792] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,800] INFO [ProducerStateManager partition=__consumer_offsets-44] Writing producer snapshot at offset 15 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:42,802] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,803] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,811] INFO [ProducerStateManager partition=__consumer_offsets-44] Writing producer snapshot at offset 15 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:42,912] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,914] INFO [ProducerStateManager partition=__consumer_offsets-44] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-44\00000000000000000015.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:42,914] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 15 in 127 ms (kafka.log.Log)
[2019-06-05 15:46:42,921] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,922] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,939] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,942] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-06-05 15:46:42,950] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,950] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,958] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,961] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-06-05 15:46:42,970] WARN [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553751882423}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:42,971] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,976] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:42,978] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:42,980] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:42,989] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:43,079] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:43,083] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:43,084] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 119 ms (kafka.log.Log)
[2019-06-05 15:46:43,091] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:43,091] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:43,097] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:43,099] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-06-05 15:46:43,109] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:43,110] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:43,116] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:43,119] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-06-05 15:46:43,127] WARN [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-5\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-5\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750682426}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:43,127] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:43,133] INFO [ProducerStateManager partition=__consumer_offsets-5] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:43,134] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:43,135] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:43,141] INFO [ProducerStateManager partition=__consumer_offsets-5] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:43,212] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:43,215] INFO [ProducerStateManager partition=__consumer_offsets-5] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-5\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:43,216] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 95 ms (kafka.log.Log)
[2019-06-05 15:46:43,222] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:43,222] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:43,233] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:43,235] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-06-05 15:46:43,242] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:43,242] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:43,258] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:43,262] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-06-05 15:46:43,270] WARN [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-8\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-8\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1559720196754}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:46:43,270] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:43,275] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:43,276] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:43,277] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:43,287] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-06-05 15:46:43,368] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:43,371] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-8\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:46:43,372] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 107 ms (kafka.log.Log)
[2019-06-05 15:46:43,378] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:46:43,378] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:43,384] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:46:43,387] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-06-05 15:46:43,391] INFO Logs loading complete in 2957 ms. (kafka.log.LogManager)
[2019-06-05 15:46:43,405] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-06-05 15:46:43,406] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-06-05 15:46:43,853] ERROR Failed to clean up log for __consumer_offsets-24 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.cleaned -> C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.swap: 另一个程序正在使用此文件，进程无法访问。

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:805)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:205)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:490)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:1978)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:1978)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:1978)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:580)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
	Suppressed: java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.cleaned -> C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.swap: 另一个程序正在使用此文件，进程无法访问。

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:802)
		... 16 more
[2019-06-05 15:46:43,857] INFO Awaiting socket connections on s0.0.0.0:9092. (kafka.network.Acceptor)
[2019-06-05 15:46:44,012] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-06-05 15:46:44,051] ERROR Failed to clean up log for __consumer_offsets-24 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.cleaned: 另一个程序正在使用此文件，进程无法访问。

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2236)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:643)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-06-05 15:46:44,053] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-06-05 15:46:44,181] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-06-05 15:46:44,182] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-06-05 15:46:44,182] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-06-05 15:46:44,181] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-06-05 15:46:44,181] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-06-05 15:46:44,277] ERROR Failed to clean up log for __consumer_offsets-24 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.cleaned: 另一个程序正在使用此文件，进程无法访问。

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2236)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:643)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-06-05 15:46:44,258] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-06-05 15:46:44,287] INFO [ReplicaManager broker=0] Stopping serving replicas in dir C:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-06-05 15:46:44,321] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-06-05 15:46:44,323] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-06-05 15:46:44,326] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-06-05 15:46:44,326] INFO Stopping serving logs in dir C:\tmp\kafka-logs (kafka.log.LogManager)
[2019-06-05 15:46:44,331] ERROR Shutdown broker because all log dirs in C:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-06-05 15:46:44,682] WARN Exception causing close of session 0x1000842cbd40002: 远程主机强迫关闭了一个现有的连接。 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-06-05 15:46:44,691] INFO Closed socket connection for client /127.0.0.1:62212 which had sessionid 0x1000842cbd40002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-06-05 15:46:52,976] INFO Expiring session 0x1000842cbd40002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:46:52,976] INFO Processed session termination for sessionid: 0x1000842cbd40002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:47:28,407] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-06-05 15:47:28,468] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-06-05 15:47:28,469] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-06-05 15:47:28,469] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-06-05 15:47:28,469] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-06-05 15:47:28,521] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-06-05 15:47:28,522] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-06-05 15:47:28,562] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,562] INFO Server environment:host.name=xqy-HP (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,562] INFO Server environment:java.version=1.8.0_111 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,563] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,563] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_111\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,563] INFO Server environment:java.class.path=C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\activation-1.1.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\argparse4j-0.7.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\audience-annotations-0.5.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\commons-lang3-3.8.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-api-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-basic-auth-extension-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-file-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-json-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-runtime-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-transforms-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\guava-20.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\hk2-api-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\hk2-locator-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\hk2-utils-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-annotations-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-core-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-databind-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-datatype-jdk8-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-jaxrs-base-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javassist-3.22.0-CR2.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.annotation-api-1.2.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.inject-1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.inject-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.servlet-api-3.1.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.ws.rs-api-2.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jaxb-api-2.3.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-client-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-common-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-container-servlet-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-container-servlet-core-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-hk2-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-media-jaxb-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-server-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-client-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-continuation-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-http-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-io-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-security-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-server-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-servlet-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-servlets-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-util-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jopt-simple-5.0.4.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-clients-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-log4j-appender-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-streams-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-streams-examples-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-streams-scala_2.12-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-streams-test-utils-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-tools-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-javadoc.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-javadoc.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-scaladoc.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-scaladoc.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-sources.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-sources.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-test-sources.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-test-sources.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-test.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-test.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\log4j-1.2.17.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\lz4-java-1.5.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\maven-artifact-3.6.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\metrics-core-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\osgi-resource-locator-1.0.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\plexus-utils-3.1.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\reflections-0.9.11.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\rocksdbjni-5.15.10.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\scala-library-2.12.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\scala-logging_2.12-3.9.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\scala-reflect-2.12.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\slf4j-api-1.7.25.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\slf4j-log4j12-1.7.25.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\snappy-java-1.1.7.2.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\validation-api-1.1.0.Final.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\zkclient-0.11.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\zookeeper-3.4.13.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\zstd-jni-1.3.8-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,567] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_111\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\oracle\product\10.2.0\db_1\bin;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Intel\iCLS Client\;C:\Program Files\Common Files\Microsoft Shared\Windows Live;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Hewlett-Packard\SimplePass;C:\Program Files\Windows Live\Shared;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\Java\jdk1.8.0_111\bin;C:\Users\xqy\Downloads\apache-maven-3.5.0-bin\apache-maven-3.5.0\bin;C:\php\php\php-5.4.45;C:\php\php\php-5.4.45\ext;C:\Program Files\Google\Chrome\Application;C:\MinGW\bin;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Users\xqy\Desktop\Download\download\gradle-4.6\bin;C:\Program Files\Git\cmd;C:\Program Files\dotnet\;C:\Program Files\PxMEWNET;C:\Program Files\ojdkbuild\java-1.10.0-openjdk-1.10.0.1-1\bin;C:\Javalib\antlr-4.7.1-complete.jar;C:\Program Files\nodejs\;C:\Program Files (x86)\STMicroelectronics\STM32 ST-LINK Utility\ST-LINK Utility;C:\Users\xqy\Desktop\apache-tomcat-9.0.0.M22 - 副本\apache-ant-1.10.5\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\PuTTY\;C:\Program Files\sbt\bin;C:\Program Files\scala\bin;C:\Users\xqy\Desktop\projects\OpenCV\opencv\build\java\x86;C:\Program Files\OpenSSL-Win32\bin;C:\Program Files\GNU Tools ARM Embedded\8 2018-q4-major\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,568] INFO Server environment:java.io.tmpdir=C:\Users\xqy\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,568] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,569] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,569] INFO Server environment:os.arch=x86 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,569] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,569] INFO Server environment:user.name=xqy (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,569] INFO Server environment:user.home=C:\Users\xqy (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,569] INFO Server environment:user.dir=C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,641] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,642] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,642] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:28,741] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-06-05 15:47:28,744] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-06-05 15:47:43,602] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-06-05 15:47:44,855] INFO starting (kafka.server.KafkaServer)
[2019-06-05 15:47:44,857] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-06-05 15:47:44,891] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-06-05 15:47:44,899] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:47:44,900] INFO Client environment:host.name=xqy-HP (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:47:44,900] INFO Client environment:java.version=1.8.0_111 (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:47:44,900] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:47:44,900] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_111\jre (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:47:44,900] INFO Client environment:java.class.path=C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\activation-1.1.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\argparse4j-0.7.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\audience-annotations-0.5.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\commons-lang3-3.8.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-api-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-basic-auth-extension-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-file-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-json-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-runtime-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\connect-transforms-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\guava-20.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\hk2-api-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\hk2-locator-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\hk2-utils-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-annotations-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-core-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-databind-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-datatype-jdk8-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-jaxrs-base-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javassist-3.22.0-CR2.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.annotation-api-1.2.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.inject-1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.inject-2.5.0-b42.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.servlet-api-3.1.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\javax.ws.rs-api-2.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jaxb-api-2.3.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-client-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-common-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-container-servlet-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-container-servlet-core-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-hk2-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-media-jaxb-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jersey-server-2.27.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-client-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-continuation-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-http-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-io-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-security-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-server-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-servlet-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-servlets-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jetty-util-9.4.14.v20181114.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\jopt-simple-5.0.4.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-clients-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-log4j-appender-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-streams-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-streams-examples-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-streams-scala_2.12-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-streams-test-utils-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka-tools-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-javadoc.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-javadoc.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-scaladoc.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-scaladoc.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-sources.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-sources.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-test-sources.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-test-sources.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-test.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0-test.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\kafka_2.12-2.2.0.jar.asc;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\log4j-1.2.17.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\lz4-java-1.5.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\maven-artifact-3.6.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\metrics-core-2.2.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\osgi-resource-locator-1.0.1.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\plexus-utils-3.1.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\reflections-0.9.11.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\rocksdbjni-5.15.10.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\scala-library-2.12.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\scala-logging_2.12-3.9.0.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\scala-reflect-2.12.8.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\slf4j-api-1.7.25.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\slf4j-log4j12-1.7.25.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\snappy-java-1.1.7.2.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\validation-api-1.1.0.Final.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\zkclient-0.11.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\zookeeper-3.4.13.jar;C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin\libs\zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:47:44,903] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_111\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\oracle\product\10.2.0\db_1\bin;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Intel\iCLS Client\;C:\Program Files\Common Files\Microsoft Shared\Windows Live;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Hewlett-Packard\SimplePass;C:\Program Files\Windows Live\Shared;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\Java\jdk1.8.0_111\bin;C:\Users\xqy\Downloads\apache-maven-3.5.0-bin\apache-maven-3.5.0\bin;C:\php\php\php-5.4.45;C:\php\php\php-5.4.45\ext;C:\Program Files\Google\Chrome\Application;C:\MinGW\bin;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Users\xqy\Desktop\Download\download\gradle-4.6\bin;C:\Program Files\Git\cmd;C:\Program Files\dotnet\;C:\Program Files\PxMEWNET;C:\Program Files\ojdkbuild\java-1.10.0-openjdk-1.10.0.1-1\bin;C:\Javalib\antlr-4.7.1-complete.jar;C:\Program Files\nodejs\;C:\Program Files (x86)\STMicroelectronics\STM32 ST-LINK Utility\ST-LINK Utility;C:\Users\xqy\Desktop\apache-tomcat-9.0.0.M22 - 副本\apache-ant-1.10.5\bin;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\PuTTY\;C:\Program Files\sbt\bin;C:\Program Files\scala\bin;C:\Users\xqy\Desktop\projects\OpenCV\opencv\build\java\x86;C:\Program Files\OpenSSL-Win32\bin;C:\Program Files\GNU Tools ARM Embedded\8 2018-q4-major\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:47:44,904] INFO Client environment:java.io.tmpdir=C:\Users\xqy\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:47:44,904] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:47:44,905] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:47:44,905] INFO Client environment:os.arch=x86 (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:47:44,905] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:47:44,905] INFO Client environment:user.name=xqy (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:47:44,905] INFO Client environment:user.home=C:\Users\xqy (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:47:44,906] INFO Client environment:user.dir=C:\Users\xqy\Desktop\github\dty717\kafka\kafka-bin (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:47:44,907] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@130745 (org.apache.zookeeper.ZooKeeper)
[2019-06-05 15:47:44,937] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-06-05 15:47:44,941] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-06-05 15:47:44,943] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62285 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-06-05 15:47:44,943] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-06-05 15:47:44,974] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62285 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:44,976] INFO Creating new log file: log.14e (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-06-05 15:47:45,019] INFO Established session 0x100088171ae0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62285 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:45,022] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100088171ae0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-06-05 15:47:45,027] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-06-05 15:47:45,110] INFO Got user-level KeeperException when processing sessionid:0x100088171ae0000 type:create cxid:0x1 zxid:0x14f txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:47:45,151] INFO Got user-level KeeperException when processing sessionid:0x100088171ae0000 type:create cxid:0x2 zxid:0x150 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:47:45,173] INFO Got user-level KeeperException when processing sessionid:0x100088171ae0000 type:create cxid:0x3 zxid:0x151 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:47:45,203] INFO Got user-level KeeperException when processing sessionid:0x100088171ae0000 type:create cxid:0x4 zxid:0x152 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:47:45,217] INFO Got user-level KeeperException when processing sessionid:0x100088171ae0000 type:create cxid:0x5 zxid:0x153 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:47:45,237] INFO Got user-level KeeperException when processing sessionid:0x100088171ae0000 type:create cxid:0x6 zxid:0x154 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:47:45,292] INFO Got user-level KeeperException when processing sessionid:0x100088171ae0000 type:create cxid:0x7 zxid:0x155 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:47:45,315] INFO Got user-level KeeperException when processing sessionid:0x100088171ae0000 type:create cxid:0x8 zxid:0x156 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:47:45,337] INFO Got user-level KeeperException when processing sessionid:0x100088171ae0000 type:create cxid:0x9 zxid:0x157 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:47:45,371] INFO Got user-level KeeperException when processing sessionid:0x100088171ae0000 type:create cxid:0xa zxid:0x158 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:47:45,392] INFO Got user-level KeeperException when processing sessionid:0x100088171ae0000 type:create cxid:0xb zxid:0x159 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:47:45,415] INFO Got user-level KeeperException when processing sessionid:0x100088171ae0000 type:create cxid:0xc zxid:0x15a txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:47:45,448] INFO Got user-level KeeperException when processing sessionid:0x100088171ae0000 type:create cxid:0xd zxid:0x15b txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-06-05 15:47:45,761] INFO Cluster ID = nZyUWUdKQ3yvmijW4epzyw (kafka.server.KafkaServer)
[2019-06-05 15:47:45,904] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-06-05 15:47:45,936] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-06-05 15:47:45,985] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-06-05 15:47:45,987] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-06-05 15:47:45,987] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-06-05 15:47:46,055] INFO Loading logs. (kafka.log.LogManager)
[2019-06-05 15:47:46,172] WARN [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\distributed-video1-0\00000000000000005274.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\distributed-video1-0\00000000000000005274.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1559717211923}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:47:46,175] INFO [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 5274 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:46,207] INFO [ProducerStateManager partition=distributed-video1-0] Writing producer snapshot at offset 5274 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:46,474] INFO [ProducerStateManager partition=distributed-video1-0] Writing producer snapshot at offset 6044 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:46,480] INFO [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 5274 (kafka.log.Log)
[2019-06-05 15:47:46,485] INFO [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 5274 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:46,490] INFO [ProducerStateManager partition=distributed-video1-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\distributed-video1-0\00000000000000005274.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:47:46,696] INFO [ProducerStateManager partition=distributed-video1-0] Writing producer snapshot at offset 6044 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:46,809] INFO [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 6044 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:46,813] INFO [ProducerStateManager partition=distributed-video1-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\distributed-video1-0\00000000000000006044.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:47:46,815] INFO [Log partition=distributed-video1-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 5274 and log end offset 6044 in 701 ms (kafka.log.Log)
[2019-06-05 15:47:46,836] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 76 (kafka.log.Log)
[2019-06-05 15:47:46,837] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 76 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:46,839] INFO [ProducerStateManager partition=javainuse-topic-0] Writing producer snapshot at offset 76 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:46,844] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 76 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:46,847] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 76 and log end offset 76 in 20 ms (kafka.log.Log)
[2019-06-05 15:47:46,856] INFO [Log partition=streams-plaintext-input-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:46,856] INFO [Log partition=streams-plaintext-input-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:46,869] INFO [Log partition=streams-plaintext-input-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:46,871] INFO [Log partition=streams-plaintext-input-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-06-05 15:47:46,878] INFO [Log partition=streams-wordcount-output-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:46,878] INFO [Log partition=streams-wordcount-output-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:46,885] INFO [Log partition=streams-wordcount-output-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:46,888] INFO [Log partition=streams-wordcount-output-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-06-05 15:47:46,896] INFO [Log partition=test-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:46,896] INFO [Log partition=test-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:46,902] INFO [Log partition=test-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:46,904] INFO [Log partition=test-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-06-05 15:47:46,914] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:46,915] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:46,922] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:46,925] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-06-05 15:47:46,934] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:46,957] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:46,962] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:46,964] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-06-05 15:47:46,972] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:46,973] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:46,978] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:46,982] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-06-05 15:47:46,995] WARN [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-11\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-11\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553753082425}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:47:46,995] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,004] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,005] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,006] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,019] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,115] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,117] INFO [ProducerStateManager partition=__consumer_offsets-11] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-11\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,118] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 128 ms (kafka.log.Log)
[2019-06-05 15:47:47,125] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,125] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,131] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,134] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-06-05 15:47:47,143] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,143] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,150] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,153] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-06-05 15:47:47,162] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,162] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,169] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,175] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-06-05 15:47:47,184] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,184] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,189] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,192] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-06-05 15:47:47,200] WARN [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750682425}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:47:47,201] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,207] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,208] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,208] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,215] INFO [ProducerStateManager partition=__consumer_offsets-16] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,292] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,294] INFO [ProducerStateManager partition=__consumer_offsets-16] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-16\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,295] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 101 ms (kafka.log.Log)
[2019-06-05 15:47:47,303] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,304] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,309] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,312] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-06-05 15:47:47,320] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,320] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,326] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,329] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-06-05 15:47:47,337] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,338] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,344] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,347] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-06-05 15:47:47,358] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,358] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,364] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,368] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-06-05 15:47:47,378] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,382] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,390] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,393] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-06-05 15:47:47,404] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,404] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,409] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,412] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-06-05 15:47:47,420] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,420] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,427] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,431] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-06-05 15:47:47,442] WARN [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-23\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-23\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750082436}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:47:47,442] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,446] INFO [ProducerStateManager partition=__consumer_offsets-23] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,447] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,448] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,460] INFO [ProducerStateManager partition=__consumer_offsets-23] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,559] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,561] INFO [ProducerStateManager partition=__consumer_offsets-23] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-23\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,561] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 125 ms (kafka.log.Log)
[2019-06-05 15:47:47,567] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Found file C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-06-05 15:47:47,568] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Deleting index files with suffix  for baseFile C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.index (kafka.log.Log)
[2019-06-05 15:47:47,573] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Found file C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2019-06-05 15:47:47,573] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Deleting index files with suffix  for baseFile C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.log (kafka.log.Log)
[2019-06-05 15:47:47,575] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Deleting index files with suffix .swap for baseFile C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.log (kafka.log.Log)
[2019-06-05 15:47:47,585] WARN [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000003.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000003.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1559720384087}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:47:47,586] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,589] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,590] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,592] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Recovering unflushed segment 3 (kafka.log.Log)
[2019-06-05 15:47:47,592] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,595] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,599] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,693] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,697] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,698] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 4 in 135 ms (kafka.log.Log)
[2019-06-05 15:47:47,710] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,713] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,720] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,724] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-06-05 15:47:47,731] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,732] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,738] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,741] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-06-05 15:47:47,748] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,748] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,756] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,762] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-06-05 15:47:47,771] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,775] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,784] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,787] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-06-05 15:47:47,795] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,796] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,802] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,805] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-06-05 15:47:47,811] WARN [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750082427}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:47:47,811] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,819] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,820] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,820] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,827] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,938] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,940] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,941] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 135 ms (kafka.log.Log)
[2019-06-05 15:47:47,948] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,950] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,955] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,958] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-06-05 15:47:47,964] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,967] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,973] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,977] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-06-05 15:47:47,983] WARN [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750682424}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:47:47,986] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:47,993] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:47,995] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:47,995] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,002] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:48,082] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,085] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:47:48,085] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 107 ms (kafka.log.Log)
[2019-06-05 15:47:48,093] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,093] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,100] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,103] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-06-05 15:47:48,113] WARN [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553756682423}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:47:48,113] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,121] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:48,122] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,123] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,129] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:48,207] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,209] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:47:48,209] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 105 ms (kafka.log.Log)
[2019-06-05 15:47:48,214] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,214] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,219] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,222] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-06-05 15:47:48,229] WARN [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750082439}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:47:48,230] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,236] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:48,237] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,237] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,244] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:48,342] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,345] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:47:48,345] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 122 ms (kafka.log.Log)
[2019-06-05 15:47:48,352] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,352] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,358] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,360] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-06-05 15:47:48,367] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,367] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,397] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,400] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-06-05 15:47:48,405] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,405] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,410] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,413] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-06-05 15:47:48,419] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,420] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,425] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,428] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-06-05 15:47:48,435] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,436] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,441] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,445] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-06-05 15:47:48,452] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,453] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,458] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,461] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-06-05 15:47:48,470] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,471] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,476] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,480] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-06-05 15:47:48,492] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,493] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,500] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,504] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-06-05 15:47:48,511] WARN [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-44\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-44\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553818654937}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:47:48,511] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,520] INFO [ProducerStateManager partition=__consumer_offsets-44] Writing producer snapshot at offset 15 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:48,521] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,521] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,529] INFO [ProducerStateManager partition=__consumer_offsets-44] Writing producer snapshot at offset 15 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:48,692] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,695] INFO [ProducerStateManager partition=__consumer_offsets-44] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-44\00000000000000000015.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:47:48,695] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 15 in 189 ms (kafka.log.Log)
[2019-06-05 15:47:48,702] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,702] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,710] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,713] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-06-05 15:47:48,720] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,720] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,728] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,732] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-06-05 15:47:48,739] WARN [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553751882423}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:47:48,739] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,744] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:48,746] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,746] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,755] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:48,837] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,841] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:47:48,842] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 108 ms (kafka.log.Log)
[2019-06-05 15:47:48,850] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,851] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,857] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,860] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-06-05 15:47:48,869] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,871] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,877] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,887] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-06-05 15:47:48,893] WARN [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-5\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-5\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1553750682426}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:47:48,893] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,899] INFO [ProducerStateManager partition=__consumer_offsets-5] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:48,901] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:48,901] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:48,908] INFO [ProducerStateManager partition=__consumer_offsets-5] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:49,016] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:49,019] INFO [ProducerStateManager partition=__consumer_offsets-5] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-5\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:47:49,019] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 131 ms (kafka.log.Log)
[2019-06-05 15:47:49,027] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:49,027] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:49,035] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:49,039] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-06-05 15:47:49,046] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:49,055] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:49,075] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:49,083] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2019-06-05 15:47:49,089] WARN [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-8\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-8\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1559720196754}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-06-05 15:47:49,089] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:49,094] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:49,096] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:49,107] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:49,113] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-06-05 15:47:49,193] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:49,195] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-8\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-06-05 15:47:49,196] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 112 ms (kafka.log.Log)
[2019-06-05 15:47:49,205] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-06-05 15:47:49,205] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:49,217] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 15:47:49,225] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-06-05 15:47:49,230] INFO Logs loading complete in 3175 ms. (kafka.log.LogManager)
[2019-06-05 15:47:49,250] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-06-05 15:47:49,251] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-06-05 15:47:49,842] ERROR Failed to clean up log for __consumer_offsets-24 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.cleaned -> C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.swap: 另一个程序正在使用此文件，进程无法访问。

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:805)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:205)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:490)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:1978)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:1978)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:1978)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:580)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
	Suppressed: java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.cleaned -> C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.swap: 另一个程序正在使用此文件，进程无法访问。

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:802)
		... 16 more
[2019-06-05 15:47:49,936] INFO Awaiting socket connections on s0.0.0.0:9092. (kafka.network.Acceptor)
[2019-06-05 15:47:50,016] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-06-05 15:47:50,018] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-06-05 15:47:50,203] ERROR Failed to clean up log for __consumer_offsets-24 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-24\00000000000000000000.timeindex.cleaned: 另一个程序正在使用此文件，进程无法访问。

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2236)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:643)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-06-05 15:47:50,207] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-06-05 15:47:50,207] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-06-05 15:47:50,208] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-06-05 15:47:50,207] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-06-05 15:47:50,209] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-06-05 15:47:50,209] INFO [ReplicaManager broker=0] Stopping serving replicas in dir C:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-06-05 15:47:50,216] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-06-05 15:47:50,220] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-06-05 15:47:50,226] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-06-05 15:47:50,226] INFO Stopping serving logs in dir C:\tmp\kafka-logs (kafka.log.LogManager)
[2019-06-05 15:47:50,232] ERROR Shutdown broker because all log dirs in C:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-06-05 15:47:50,586] WARN Exception causing close of session 0x100088171ae0000: 远程主机强迫关闭了一个现有的连接。 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-06-05 15:47:50,587] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62285 which had sessionid 0x100088171ae0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-06-05 15:47:58,976] INFO Expiring session 0x100088171ae0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-06-05 15:47:58,976] INFO Processed session termination for sessionid: 0x100088171ae0000 (org.apache.zookeeper.server.PrepRequestProcessor)
